
The ***inverted index*** contains a sorted list of all of the unique values, or terms, that occur in any document and, for each term, a list of all the documents that contain it.

The inverted index that is written to disk is ***immutable***: it doesn’t change. Ever. This immutability has important benefits:

* There is no need for locking.

* Once the index has been read into the kernel’s filesystem cache, it stays there, because it never changes.

* Any other caches (like the filter cache) remain valid for the life of the index.

* Writing a single large inverted index allows the data to be compressed



If you want to make new documents searchable, you have to rebuild the entire index. This places a significant limitation either on the amount of data that an index can contain, or the frequency with which the index can be updated.

这一块具体的限制，　其实也就是inverted index的实现

The next problem that needed to be solved was how to make an inverted index updatable without losing the benefits of immutability? The answer turned out to be: ***use more than one index***.


A segment is an inverted index in its own right(独立的), but now the word index in Lucene came to mean a collection of segments plus a commit point—a file that lists all known segments

```
commit point  -----> segement
              -----> segement
              -----> segement
```

```
luncene index <--> elasticsearch shard

elasticsearch index   -----> elasticsearch shard
                      -----> elasticsearch shard
                      -----> elasticsearch shard
```


### create

per segement search work as follow:
1. New documents are collected in an in-memory indexing buffer.
2. Every so often, the buffer is commited:

    * A new segment—a supplementary inverted index—is written to disk.
    * A new commit point is written to disk, which includes the name of the new segment.
    * The disk is fsync’ed—all writes waiting in the filesystem cache are flushed to disk, to ensure that they have been physically written.

3. The new segment is opened, making the documents it contains visible to search.
4. The in-memory buffer is cleared, and is ready to accept new documents.


### delete

Segments are immutable, so documents cannot be removed from older segments, nor can older segments be updated to reflect a newer version of a document. Instead, every commit point includes a `.del` file that lists which documents in which segments have been deleted.

### update

when a document is updated, the old version of the document is marked as deleted, and the new version of the document is indexed in a new segment. Perhaps both versions of the document will match a query, but the older deleted version is removed before the query results are returned.

### searchable

新的document变为可以search还需要很久的事件.瓶颈在磁盘,fsync会把segement写入磁盘,对性能冲击很大.写入文件缓存可以保证能够被search到.(refresh API)

每个shard每隔1秒都会自动refresh.

Elasticsearch has ***near real-time*** search: document changes are not visible to search immediately, but will become visible within 1 second.


```
POST /_refresh

POST /blogs/_refresh
```

##　transaction log


1. When a document is indexed, it is added to the in-memory buffer and appended to the translog

2. The refresh leaves the shard in the state depicted. Once every second, the shard is refreshed:
  * The docs in the in-memory buffer are written to a new segment, without an fsync.
  * The segment is opened to make it visible to search.
  * The in-memory buffer is cleared.

3. This process continues with more documents being added to the in-memory buffer and appended to the transaction log

4. Every so often—such as when the translog is getting too big—the index is flushed; a new translog is created, and a full commit is performed
  * Any docs in the in-memory buffer are written to a new segment.
  * The buffer is cleared.
  * A commit point is written to disk.
  * The filesystem cache is flushed with an fsync.
  * The old translog is deleted.

flush API - The action of performing a commit and truncating the translog is known in Elasticsearch as a flush.

```
POST /blogs/_flush

POST /_flush?wait_for_ongoing

```


By default, the translog is fsync'ed every 5 seconds and after a write request completes


## merge segement

With the automatic refresh process creating a new segment every second(每秒的refresh会创建新的segement?!)

Elasticsearch solves this problem by merging segments in the background.

It happens automatically while you are indexing and searching.

1. While indexing, the refresh process creates new segments and opens them for search.
2. The merge process selects a few segments of similar size and merges them into a new bigger segment in the background. This does not interrupt indexing and searching.
3.
  * The new segment is flushed to disk.
  * A new commit point is written that includes the new segment and excludes the old, smaller segments.
  * The new segment is opened for search.
  * The old segments are deleted.


The merging of big segments can use a lot of I/O and CPU, which can hurt search performance if left unchecked. By default, Elasticsearch throttles the merge process so that search still has enough resources available to perform well.


#### optimized API

```

POST /logstash-2014-10/_optimize?max_num_segments=1

``
