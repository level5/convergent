# 索引

索引对应数据库中的表， 文档对应成数据库表中的一条记录。  

* index是一个逻辑的namespace，他指向一个或者多个物理的shard
* shard是一个Lucene的instance，他有完整的search engine。

  a shard is a single instance of Lucene, and is a complete search engine in its own right
* shard是数据存放的地方。
* primary shard和replica shard.
  - 每一个document都属于一个primary shard
  - replica shard就是primary shard的一份拷贝
  - replica shard的作用就是数据备份和提供给查询使用
  - primary shard和replica shard不会保存在同一个node中。

    It doesn’t make sense to store copies of the same data on the same node.If we were to lose that node, we would lose all copies of our data.
* 新index进来的document，会先保存在primary shard上，然后再被复制到replica shard上。
## Document

document refers to the top-level, or root object that is serialized into JSON and stored in Elasticsearch under a unique ID.

### Document metadata

* `_index`

  This name must be lowercase, cannot begin with an underscore, and cannot contain commas
* `_type`

  A `_type` name can be lowercase or uppercase, but shouldn’t begin with an underscore or contain commas
* `_id`

  一个string。在elasticsearch中，`_id`, `_index`和`_type`一起能唯一确定一个document。
  在保存document的时候，可以自己提供，也可以由elasticsearch来创建。
  > Autogenerated IDs are 20 character long, URL-safe, Base64-encoded GUID strings

### index settings

可以禁止automatic creation
`config/elasticsearch.yml`
```
action.auto_create_index: false
```

```
PUT /my_index
{
    "settings": { ... any settings ... },
    "mappings": {
        "type_one": { ... any mappings ... },
        "type_two": { ... any mappings ... },
        ...
    }
}
```

#### delete index

```
DELETE /my_index

DELETE /index_one,index_two
DELETE /index_*

DELETE /_all
DELETE /*
```

如果担心误删，可以配置`elasticsearch.yml`:
```
action.destructive_requires_name: true
```
这样就需要删除index的名字，而不能使用`_all`和匹配符来删除


#### `settings`

* number_of_shards:
* number_of_replicas:
* analysis:

创建：
```
PUT /my_temp_index
{
    "settings": {
        "number_of_shards" :   1,
        "number_of_replicas" : 0
    }
}
```
动态修改replicas的数量
```
PUT /my_temp_index/_settings
{
    "number_of_replicas": 1
}
```

对于非global的analyzer，需要制定index的名字。
```
GET /spanish_docs/_analyze?analyzer=es_std
El veloz zorro marrón
```

##### analyzer
1. Character filters 在做tokenized之前整理字符串，比如去掉HTML标签
2. Tokenizers 分词
3. Token filters 处理tokenized之后的分词

```
PUT /my_index
{
    "settings": {
        "analysis": {
            "char_filter": { ... custom character filters ... },
            "tokenizer":   { ...    custom tokenizers     ... },
            "filter":      { ...   custom token filters   ... },
            "analyzer":    { ...    custom analyzers      ... }
        }
    }
}
```

例子

```
PUT /my_index
{
    "settings": {
        "analysis": {
            "char_filter": {
                "&_to_and": {
                    "type":       "mapping",
                    "mappings": [ "&=> and "]
            }},
            "filter": {
                "my_stopwords": {
                    "type":       "stop",
                    "stopwords": [ "the", "a" ]
            }},
            "analyzer": {
                "my_analyzer": {
                    "type":         "custom",
                    "char_filter":  [ "html_strip", "&_to_and" ],
                    "tokenizer":    "standard",
                    "filter":       [ "lowercase", "my_stopwords" ]
            }}
}}}
```

test

```
GET /my_index/_analyze?analyzer=my_analyzer
The quick & brown fox
```

使用创建的analyzer

```
PUT /my_index/_mapping/my_type
{
    "properties": {
        "title": {
            "type":      "string",
            "analyzer":  "my_analyzer"
        }
    }
}
```

#### type

Types can be useful abstractions for partitioning similar-but-not-identical data

Lucene has no concept of document types, the type name of each document is stored with the document in a metadata field called `_type`

Lucene also has no concept of mappings. Mappings are the layer that Elasticsearch uses to map complex JSON documents into the simple flat documents that Lucene expects to receive.

discussion:
* Technically, multiple types may live in the same index as long as their fields do not conflict (either because the fields are mutually exclusive, or because they share identical fields)
* types are useful when you need to discriminate between different segments of a single collection. The overall "shape" of the data is identical (or nearly so) between the different segments.
* Types are not as well suited for entirely different types of data. If your two types have mutually exclusive sets of fields, that means half your index is going to contain "empty" values (the fields will be sparse), which will eventually cause performance problems. In these cases, it’s much better to utilize two independent indices.


summary:
* ***Good***: `kitchen` and `lawn-care` types inside the `products` index, because the two types are essentially the same schema
* ***Bad***: `products` and `logs` types inside the `data` index, because the two types are mutually exclusive. Separate these into their own indices.

#### The Root object

##### proerties

* type
* index
* analyzer

##### `_source`

可以disable掉：
```
PUT /my_index
{
    "mappings": {
        "my_type": {
            "_source": {
                "enabled":  false
            }
        }
    }
}
```

Besides indexing the values of a field, you can also choose to store the original field value for later retrieval.

In Elasticsearch, setting individual document fields to be stored is usually a false optimization. The whole document is already stored as the `_source` field. It is almost always better to just extract the fields that you need by using the `_source` parameter.

##### `_all`

同样可以disable掉
```
PUT /my_index/_mapping/my_type
{
    "my_type": {
        "_all": { "enabled": false }
    }
}
```

默认每个字段都是`include_in_all`,可以修改这个默认值，然后在自己需要的字段配置
```
PUT /my_index/my_type/_mapping
{
    "my_type": {
        "include_in_all": false,
        "properties": {
            "title": {
                "type":           "string",
                "include_in_all": true
            },
            ...
        }
    }
}
```

给`_all`字段配置analyzer
```
PUT /my_index/my_type/_mapping
{
    "my_type": {
        "_all": { "analyzer": "whitespace" }
    }
}
```

#### Metadata: Document Identity

* `_id`
* `_type`
* `_index`
* `_uid`  The `_type` and `_id` concatenated together as type#id

By default, the `_uid` field is stored (can be retrieved) and indexed (searchable). The `_type` field is indexed but not stored, and the `_id` and `_index` fields are neither indexed nor stored, meaning they don’t really exist.


#### Dynamic Mapping

 you can control this behavior with the `dynamic` setting, which accepts the following options:
 * true 默认设置，动态添加新字段
 * false 忽略新字段
 * strict 出现不知道的字段时抛异常

 The dynamic setting may be applied to the root object or to any field of type object. You could set dynamic to strict by default, but enable it just for a specific inner objec

 > Setting dynamic to false doesn’t alter the contents of the `_source` field at all. The `_source` will still contain the whole JSON document that you indexed. However, any unknown fields will not be added to the mapping and will not be searchable.


##### date_detection
```
PUT /my_index
{
    "mappings": {
        "my_type": {
            "date_detection": false
        }
    }
}
```
##### dynamic_templates
* Each template has a name, which you can use to describe what the template does
* a `mapping` to specify the mapping that should be applied
* and at least one parameter (such as match) to define which fields the template should apply to
* Templates are checked in order; the first template that matches is applied.
* The `match_mapping_type` allows you to apply the template only to fields of the specified type, as detected by the standard dynamic mapping rules
* The `match` parameter matches just the field name, and the `path_match` parameter matches the full path to a field in an object, so the pattern `address.*.name` would match a field like this
  ```
  {
      "address": {
          "city": {
              "name": "New York"
          }
      }
  }
  ```
* The `unmatch` and `path_unmatch` patterns can be used to exclude fields that would otherwise match.

```
PUT /my_index
{
    "mappings": {
        "my_type": {
            "dynamic_templates": [
                { "es": {
                      "match":              "*_es",
                      "match_mapping_type": "string",
                      "mapping": {
                          "type":           "string",
                          "analyzer":       "spanish"
                      }
                }},
                { "en": {
                      "match":              "*",
                      "match_mapping_type": "string",
                      "mapping": {
                          "type":           "string",
                          "analyzer":       "english"
                      }
                }}
            ]
}}}
```

#### 默认配置

* It can be more convenient to specify these common settings in the `_default_` mapping.  
* The `_default_` mapping acts as a template for new types.  
* All types created after the `_default_` mapping will include all of these default settings, unless explicitly overridden in the type mapping itself.
* The `_default_` mapping can also be a good place to specify index-wide dynamic templates.

#### reindexing

* Although you can add new types to an index, or add new fields to a type, you can’t add new analyzers or make changes to existing fields. If you were to do so, the data that had already been indexed would be incorrect and your searches would no longer work as expected.

* The simplest way to apply these changes to your existing data is to reindex: create a new index with the new settings and copy all of your documents from the old index to the new index.

#### 别名

There are two endpoints for managing aliases: `_alias` for single operations, and `_aliases` to perform multiple operations ***atomically***.

创建一个index，并定义一个别名
```
PUT /my_index_v1
PUT /my_index_v1/_alias/my_index
```

查看别名指向的index，或者指定index的别名
```
GET /*/_alias/my_index
GET /my_index_v1/_alias/*
```

创建新的index之后，原子的切换别名
```
POST /_aliases
{
    "actions": [
        { "remove": { "index": "my_index_v1", "alias": "my_index" }},
        { "add":    { "index": "my_index_v2", "alias": "my_index" }}
    ]
}
```



### Document

* Documents in Elasticsearch are immutable

* 当修改或者覆盖存在的document的时候，在内部，elasticsearch将老的document标记未deleted并且添加新的document。老的document不会立即消失。elasticsearch会在添加更多的document的时候删除他们

* 部分修改时
  1. Retrieve the JSON from the old document
  2. Change it
  3. Delete the old document
  4. Index a new document

#### 确保新创建一个document

* 通过POST请求,由elasticsearch来自动生成`_id`
* PUT　带上查询参数`op_type=create`
* PUT URL最后戴上`/_create`


### 乐观锁

#### 使用自带version

所有修改和删除的API都接受`version`这个参数来使用乐观锁控制这次修改。

```bash
PUT /website/blog/1?version=1
{
  "title": "My first blog entry",
  "text":  "Starting to get the hang of this..."
}
```


```bash
# 使用外部的version。
PUT /website/blog/2?version=5&version_type=external
{
  "title": "My first external blog entry",
  "text":  "Starting to get the hang of this..."
}
```

#### 使用external的version

不单只修改删除，创建时也可以使用
```
PUT /website/blog/2?version=5&version_type=external
{
  "title": "My first external blog entry",
  "text":  "Starting to get the hang of this..."
}
```

```
{
  "_index":   "website",
  "_type":    "blog",
  "_id":      "2",
  "_version": 5,
  "created":  true
}
```


### 部分修改

It is still possible that a request from another process could change the document before update has managed to reindex it.

* 如果无所谓，只需要重试的话带上参数`retry_on_conflict=5`,表示重试５次才失败。

###　取得多个结果
```
GET /_mget
{
   "docs" : [
      {
         "_index" : "website",
         "_type" :  "blog",
         "_id" :    2
      },
      {
         "_index" : "website",
         "_type" :  "pageviews",
         "_id" :    1,
         "_source": "views"
      }
   ]
}
```

```
GET /website/blog/_mget
{
   "docs" : [
      { "_id" : 2 },
      { "_type" : "pageviews", "_id" :   1 }
   ]
}
```

```
GET /website/blog/_mget
{
   "ids" : [ "2", "1" ]
}
```
这个查询即使有一个没有查到也是返回２００，需要判断结果中对应位置的对象的`found`字段


### 修改多个结果

bulk

* bulk requests are not atomic: they cannot be used to implement transactions.
* 通过测试找到合适的bulk大小。A good place to start is with batches of 1,000 to 5,000 documents or, if your documents are very large, with even smaller batches.　A good bulk size to start playing with is around 5-15MB in size
* 格式：
  ```
  { action: { metadata }}\n
  { request body        }\n
  { action: { metadata }}\n
  { request body        }\n
  ...
  ```
* Every line must end with a newline character (\n), including the last line. These are used as markers to allow for efficient line separation
* The lines cannot contain unescaped newline characters, as they would interfere with parsing. This means that the JSON must not be pretty-printed.
* The action/metadata line specifies what action to do to which document.
  - `create`
  - `index` 新增或者替换
  - `update`
  - `delete`
* The metadata should specify the `_index`, `_type`, and `_id` of the document to be indexed, created, updated, or deleted
* 对于create和update, The request body line consists of the document `_source` itself
* 对于update, ...
* 对于delete,不需要body
